# GPU ML Execution Primitives Research

## Objective
Build a deep understanding of how GPUs execute machine learning workloads,
with a focus on translating GPU efficiency to CPU-scale inference.

## Scope
- GPU architecture taxonomy (NVIDIA, AMD)
- Tensor / Matrix cores across generations
- GEMM and attention execution analysis
- Memory hierarchy and latency hiding
- Kernel optimization techniques
- Workload bottleneck classification
- CPU implications for ML inference
